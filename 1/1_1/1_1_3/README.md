[Home](./../../../README.md) | [인공 지능 딥러닝의 이해](./../../README.md) | [인공 신경망의 이해](./../README.md) | 인공 신경 살펴보기

## 인공 신경 살펴보기
앞서 인공 신경망에 대해 살펴보았다. 그러면 인공 신경망은 무엇으로 구성될까?<br>
여기서는 인공 신경망을 구성하는 인공 신경에 대해 생물학적 신경과 비교해 보면서 그 내부 구조를 살펴보겠다.

### 인공 신경과 생물학적 신경
인공 신경망의 구성요소는 인공 신경이다.<br>
인공 신경이라는 이름은 생물학적으로부터 얻어졌다.<br>
인공 신경은 우리 두뇌의 구성 요소 중 하나인 생물학적 신경의 동작을 따라 만들어진 모형(model)이다.<br>

생물학적 신경의 구성
1. 신호를 받기 위한 여러 개의 가지돌기(dendrites)
2. 입력받은 신호를 처리하기 위한 신경 세포체(cell body)
3. 다른 신경들로 신호를 내보내기 위한 축삭돌기(axon)

![Image](https://github.com/user-attachments/assets/832e5bc8-822b-44c5-9dcc-481fd7333462)

특히 축삭돌기 말단과 다음 신경의 가지돌기 사이의 틈을 시냅스라고 한다.

![Image](https://github.com/user-attachments/assets/78f65d96-54c3-4114-9a93-9148ed725ecc)

시냅스는 신경근 접합부라고도 하며 한 신경에서 다른 신경으로 신호를 전달하는 연결지점을 말한다.

인공 신경은 데이터를 받기 위한 여러 개의 입력부, 입력받은 데이터를 처리하는 처리부, 그리고 여러 개의 다른 인공 신경들로 연결될 수 있는 하나의 출력부를 가진다.<br>
특히 인공 신경의 출력부에는 다음 인공 신경의 입력부에 맞는 형태의 데이터 변환을 위한 활성화함수가 있다.

![Image](https://github.com/user-attachments/assets/286945c9-412a-42b0-a5c3-390419c77869)

### 인공 신경 내부 살펴보기
이제 인공 신경 안으로 들어가 보겠다.<br>
인공 신경은 세 개의 처리 단계를 수행한다.

![Image](https://github.com/user-attachments/assets/ec5be06a-c9d3-448f-92e7-6a5df86ac494)

**1 각각의 입력 값은 가중치에 의해 커지거나 작아진다.**<br>
하나의 입력 신호(데이터)가 들어올 때 그 신호는 그 입력에 할당된 하나의 가중치(weight)에 의해 곱해진다.<br>
예를 들어, 하나의 인공 신경이 그림과 같이 3개의 입력을 가진다면, 그 인공 신경은 각 입력에 적용될 수 있는 3개의 가중치를 가진다.<br>
학습 과정에서 인공 신경망은 결과 값과 목표 값의 오차를 기반으로 가중치들을 조정한다.<br>
생물학적 신경의 가지돌기가 그 두께에 따라 신호가 더 잘 전달되거나 덜 전달되는 것처럼 인공 신경의 가중치도 그 값에 따라 신호(데이터)가 커지거나 작아진다.<br>
가중치는 다른 말로 강도(strength)라고도 한다. 즉, 가중치는 입력 신호가 전달되는 강도를 결정한다.<br>
입력 신호가 작더라도 가중치가 크면 신호가 커지며, 입력 신호가 크더라도 가중치가 작으면 내부로 전달되는 신호는 작아진다.<br>
인공 신경의 가중치는 생물학적 신경의 가지돌기의 두께로 비유할 수 있다.

**2 모든 입력 신호들은 더해진다.**<br>
가중치에 의해 곱해진 입력 신호들은 하나의 값으로 더해진다.<br>
그리고 추가적으로 보정 값(offset)도 하나 더해진다.<br>
이 보정값은 편향(bias)이라고 불린다.<br>
인공 신경망은 학습 과정에서 편향도 조정한다.<br>
편향은 하나로 더해진 입력 신호에 더해지는 신호로 신호를 좀 더 크게 하거나 또는 좀 더 작게 하는 역할을 한다.<br>
즉, 신호를 조금 더 강화하거나 조금 더 약화하는 역할을 한다.

**3 신호를 활성화한다.**<br>
앞에서 더해진 입력신호들은 활성화함수를 거쳐 하나의 출력 신호로 바뀐다.<br>
활성화 함수는 신호 전달 함수라고도 하며 신호의 형태를 다른 인공 신경의 입력에 맞게 변경하여 출력하는 역할을 한다.<br>
생물학적 신경을 시냅스가 연결하는 것처럼 활성화함수는 인공 신경을 연결하는 역할을 수행한다.

다음은 인공 신경망에 사용되는 활성화함수이다.<br>
활성화 함수는 인공 신경망의 활용 영역에 따라 달리 사용된다.

![Image](https://github.com/user-attachments/assets/af0ae9b5-8b56-4f1c-aacd-bb1da8c384e4)

일반적으로 출력 값을 0에서 1사이의 값으로 하고자 할 경우엔 sigmoid 함수, 출력값을 -1에서 1사이의 값으로 하고자 할 경우엔 tanh 함수, 0보다 큰 출력 값만 내보내고자 할 경우엔 relu 함수를 사용한다.<br>
특히 다음은 분류를 위해 출력 층에 사용할 수 있는 활성화 함수이다.

![Image](https://github.com/user-attachments/assets/5d7a576b-0cb9-4ffe-bc2a-2bd22f920572)

여기까지는 활성화 함수로 이러한 함수들이 사용된다는 정도로 이해하고 넘어가자.

### 인공 신경 함수 수식

다음은 하나의 인공 신경과 그 인공 신경으로 들어가는 입력 값 x의 집합, 입력 값에 대한 가중치(신호 강도) w의 집합, 편향 입력 값 1, 편향 b, 가중치와 편향을 통해 들어오는 입력 값들의 합, 그 합을 입력으로 받는 활성화 함수 f, 활성화 함수 f의 출력 out을 나타낸다.

![Image](https://github.com/user-attachments/assets/ddbb4f4e-615c-4b90-b1b8-18bf4109be73)

인공 신경의 수식은 일반적으로 다음과 같다.
```math
\begin{aligned}
out& = f(x_1 \times w_1 + x_2 \times w_2 + x_3 \times w_3 + ... + x_n \times w_n + 1 \times b)\\
out& = f(\displaystyle\sum_{i=1}^n{x_i \times w_i + 1 \times b})
\end{aligned}
```

예를 들어, 활성화 함수가 sigmoid 함수일 경우 인공 신경의 수식은 다음과 같다.
```math
\begin{aligned}
out&= \frac{1}{1+e^{x_1 \times w_1 + x_2 \times w_2 + x_3 \times w_3 + ... + x_n \times w_n + 1 \times b}}\\
out&= \frac{1}{1+e^{\displaystyle\sum_{i=1}^n{x_i \times w_i + 1 \times b}}}
\end{aligned}
```

또 활성화 함수가 relu 함수일 경우 인공 신경의 수식은 다음과 같습니다.
```math
\begin{aligned}
out&= max(0, x_1 \times w_1 + x_2 \times w_2 + x_3 \times w_3 + ... + x_n \times w_n + 1 \times b)\\
out&= max(0, \displaystyle\sum_{i=1}^n{x_i \times w_i + 1 \times b})
\end{aligned}
```

이러한 수식들은 추후 자세히 구현해 보면서 그 동작들을 이해할 것이다.

이상으로 인간의 두뇌를 모델로 한 인공 신경망, 인공 신경망으로 할 수 있는 일들, 인공 신경망의 구조, 인공 신경망의 학습 방법, 생물학적 신경과 인공 신경과의 관계, 인공 신경의 구성 요소를 살펴보았다.<br>
이 과정에서 인공 신경의 수식은 생물학적 신경으로부터 직관적으로 유도된 것을 알았다.<br>
인공 신경의 수식은 간단한 형태의 수식이지만 이러한 인공 신경으로 망을 구성할 때는 아주 큰 힘을 발휘하게 된다.
