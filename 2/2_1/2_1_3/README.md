[Home](./../../../README.md) | [인공 지능의 딥러닝 알고리즘](./../../README.md) | [딥러닝 동작 원리 이해하기](./../README.md) | $y = 3 \times x + 1$ 학습시켜 보기

## $y = 3 \times x + 1$ 학습시켜 보기
여기서는 다음과 같은 숫자들의 집합 X, Y를 이용하여, 단일 인공 신경을 합습시켜 보겠다.  
![Image](https://github.com/user-attachments/assets/463bb056-4c92-4d5e-b705-dd835804d136)  
![Image](https://github.com/user-attachments/assets/408627ee-0d03-497d-bb58-c7ea75d02f03)  

그래서 다음 함수를 근사하는 인공 신경 함수를 만들어 보도록 하자.

$y = f(x) = 3 \times x + 1$ ($x$는 실수)  

인공 신경을 학습시키는 과정은 w, b 값을 X, Y 값에 맞추어 가는 과정이다.  
그래서 학습이 진행됨에 따라 w 값은 3에 가까운 값으로, b 값은 1에 가까운 값으로 이동하게 된다.

다음과 같이 예제를 작성하자.
```python
xs = [-1., 0., 1., 2., 3., 4.]
ys = [-2., 1., 4., 7., 10., 13.]
w = 10.
b = 10.

y = xs[0]*w + 1*b
print(f'x  = {xs[0]:6.3f}, y  = {y:6.3f}')

t = ys[0]
E = (y - t)**2/2
print(f'E  = {E:.7f}')

yb = y - t
wb = yb*xs[0]
bb = yb*1
print(f'wb = {wb:6.3f}, bb = {bb:6.3f}')

lr = 0.01
w = w - lr*wb
b = b - lr*bb
print(f'w  = {w:6.3f}, b  = {b:6.3f}')
```
- 실수 형 리스트 변수 xs, ys를 선언한 후, 다음 X, Y 값으로 초기화 한다.  
![Image](https://github.com/user-attachments/assets/ca858122-165c-4a2b-acc0-5b44c8d2a7aa)  
숫자 뒤에 점(.)은 실수를 나타낸다.
- 입력 값의 가중치 값을 저장할 변수 w를 선언한 후, 10.으로 초기화한다.  
10.은 임의로 선택한 값이다.  
입력 값의 가중치는 입력 값의 강도, 세기라고도 하며 입력 값을 증폭 시키거나 감소시키는 역할을 한다.  
인공 신경도 가지 돌기의 두께에 따라 입력 신호가 증폭되거나 감소될 수 있는데, 이런 관점에서 가중치는 가지돌기의 두께에 해당되는 변수로 생각할 수 있다.  
![Image](https://github.com/user-attachments/assets/3e37c9dc-b880-40b3-bb13-78c4c8238916)
- 인공 신경의 편항 값을 저장할 변수 b를 선언한 후, 10.으로 초기화한다.  
10.은 임의로 선택한 값이다.  
편향 값은 가중치를 거친 입력 값의 합(=전체 입력신호)에 더해지는 값으로 입력신호를 좀 더 세게 해주거나 약하게 하는 역할을 한다.
- 다음과 같이 단일 인공 신경을 수식으로 표현한다.  
![Image](https://github.com/user-attachments/assets/1c034686-5280-4353-b182-18994831b123)$y = xw + 1b = xw + b$  
일단 xs[0] 항목을 w에 곱한 후, b를 더해준 후, 변수 y에 대입해 준다.  
이 과정에서 순전파가 이루어진다.  
즉, xs[0] 항목이 w에 곱해지고 b와 더해져 y에 도달하는 과정을 순전파라고 한다.  
순전파 결과 얻어진 y값을 인공 신경망에 의한 예측 값이라고 한다.
- print 함수를 호출하여 xs[0], y 값을 출력한다.
- 변수 t를 선언한 후, ys[0]값을 받는다.  
ys[0]은 인공 신경망에 대한 xs[0]값의 목표 값이다.
- 변수 E를 선언한 후, 다음과 같은 형태의 수식을 구현한다.  
$E=\frac{1}{2}(y-t)^2$  
y의 값이 t에 가까울수록 E의 값은 0에 가까워진다.  
즉, 오차 값이 0에 가까워진다.  
이 수식을 오차함수 또는 손실함수 또는 비용함수라고 한다.
- print 함수를 호출하여 E 값을 출력한다.  
소수점 이하 7자리까지 출력한다.
- yb 변수를 선언한 후, 순전파 결과 값에서 목표 값을 빼 오차 값을 넣어준다.
- wb 변수를 선언한 후, 가중치 값에 대한 역전파 값을 받는다.
- bb 변수를 선언한 후, 편향 값에 대한 역전파 값을 받는다.
- print 함수를 호출하여 역전파 결과 값 wb, bb를 출력한다.  
소수점 이하 3자리까지 출력한다.
- 학습률 변수 lr을 선언한 후, 0.01로 초기화한다.
- wb 역전파 값에 학습률을 곱한 후, w값에서 빼준다.  
이 과정에서 w 변수에 대한 학습이 이루어진다.
- bb 역전파 값에 학습률을 곱한 후, b값에서 빼준다.  
이 과정에서 b 변수에 대한 학습이 이루어진다.
- print 함수를 호출하여 학습이 1회 수행된 w, b 값을 출력한다.  
소수점 이하 3자리까지 출력한다.

다음은 실행 결과 화면이다.
```
x  = -1.000, y  =  0.000
E  = 2.0000000
wb = -2.000, bb =  2.000
w  = 10.020, b  =  9.980
```
w, b 값이 각각 10.020, 9.980으로 표시되는 것을 확인한다.
<br>
<br>

### 전체 입력 데이터 학습 수행하기
이제 다음 좌표값 전체에 대해 1회 학습을 수행해 보자.  
![Image](https://github.com/user-attachments/assets/ca858122-165c-4a2b-acc0-5b44c8d2a7aa)  

다음과 같이 예제를 수정한다.
```python
xs = [-1., 0., 1., 2., 3., 4.]
ys = [-2., 1., 4., 7., 10., 13.]
w = 10.
b = 10.

for n in range(6):

    y = xs[n]*w + 1*b
    print(f'x  = {xs[0]:6.3f}, y  = {y:6.3f}')

    t = ys[n]
    E = (y - t)**2/2
    print(f'E  = {E:.7f}')

    yb = y - t
    wb = yb*xs[n]
    bb = yb*1
    print(f'wb = {wb:6.3f}, bb = {bb:6.3f}')

    lr = 0.01
    w = w - lr*wb
    b = b - lr*bb
    print(f'w  = {w:6.3f}, b  = {b:6.3f}')

    print('='*25)
```
- n값을 0에서 6 미만까지 바꾸어가며 위 과정을 6회 수행한다.
- xs[0]을 xs[n]으로 변경한다.
- ys[0]을 ys[n]으로 변경한다.
- 실행 경계를 표시하기 위해 '='을 25개 출력한다.

다음은 실행 결과 화면이다.
```
x  = -1.000, y  =  0.000
E  = 2.0000000
wb = -2.000, bb =  2.000
w  = 10.020, b  =  9.980
=========================
x  = -1.000, y  =  9.980
E  = 40.3202000
wb =  0.000, bb =  8.980
w  = 10.020, b  =  9.890
=========================
x  = -1.000, y  = 19.910
E  = 126.5672320
wb = 15.910, bb = 15.910
w  =  9.861, b  =  9.731
=========================
x  = -1.000, y  = 29.453
E  = 252.0662245
wb = 44.906, bb = 22.453
w  =  9.412, b  =  9.507
=========================
x  = -1.000, y  = 37.742
E  = 384.8117627
wb = 83.226, bb = 27.742
w  =  8.580, b  =  9.229
=========================
x  = -1.000, y  = 43.547
E  = 466.5735925
wb = 122.190, bb = 30.547
w  =  7.358, b  =  8.924
=========================
```
<br>
<br>

### 가중치, 편향 학습과정 살펴보기
가중치와 편향 값만 확인해 보겠다.

다음과 같이 예제를 수정한다.
```python
xs = [-1., 0., 1., 2., 3., 4.]
ys = [-2., 1., 4., 7., 10., 13.]
w = 10.
b = 10.

for n in range(6):

    y = xs[n]*w + 1*b

    t = ys[n]
    E = (y - t)**2/2

    yb = y - t
    wb = yb*xs[n]
    bb = yb*1

    lr = 0.01
    w = w - lr*wb
    b = b - lr*bb
    print(f'w  = {w:6.3f}, b  = {b:6.3f}')
```
- w, b에 대한 출력만 한다.  
나머치 출력 루틴은 지워준다.

다음은 실행 결과 화면이다.
```
w  = 10.020, b  =  9.980
w  = 10.020, b  =  9.890
w  =  9.861, b  =  9.731
w  =  9.412, b  =  9.507
w  =  8.580, b  =  9.229
w  =  7.358, b  =  8.924
```
학습 회수에 따라 w, b값이 바뀌는 것을 확인한다.
<br>
<br>

### 반복 학습 2회 수행하기
여기서는 반복 학습 2회를 수행해 보겠다.

다음과 같이 예제를 수정한다.
```python
xs = [-1., 0., 1., 2., 3., 4.]
ys = [-2., 1., 4., 7., 10., 13.]
w = 10.
b = 10.

for epoch in range(2):

    for n in range(6):

        y = xs[n]*w + 1*b

        t = ys[n]
        E = (y - t)**2/2

        yb = y - t
        wb = yb*xs[n]
        bb = yb*1

        lr = 0.01
        w = w - lr*wb
        b = b - lr*bb
        print(f'w  = {w:6.3f}, b  = {b:6.3f}')
```
- epoch값을 0에서 2 미만까지 바꾸어가며 2회 반복을 수행한다.

다음은 실행 결과 화면이다.
```
w  = 10.020, b  =  9.980
w  = 10.020, b  =  9.890
w  =  9.861, b  =  9.731
w  =  9.412, b  =  9.507
w  =  8.580, b  =  9.229
w  =  7.358, b  =  8.924
w  =  7.393, b  =  8.888
w  =  7.393, b  =  8.809
w  =  7.271, b  =  8.687
w  =  6.947, b  =  8.525
w  =  6.366, b  =  8.331
w  =  5.534, b  =  8.123
```
학습 회수에 따라 w, b값이 바뀌는 것을 확인한다.
<br>
<br>

### 반복 학습 20회 수행하기
다음과 같이 예제를 수정한다.
```python
xs = [-1., 0., 1., 2., 3., 4.]
ys = [-2., 1., 4., 7., 10., 13.]
w = 10.
b = 10.

for epoch in range(20):

    for n in range(6):

        y = xs[n]*w + 1*b

        t = ys[n]
        E = (y - t)**2/2

        yb = y - t
        wb = yb*xs[n]
        bb = yb*1

        lr = 0.01
        w = w - lr*wb
        b = b - lr*bb
        if epoch % 2 == 1 and n == 0:
            print(f'w  = {w:6.3f}, b  = {b:6.3f}')
```
- epoch값을 0에서 20 미만까지 바꾸어가며 20회 반복을 수행한다.
- epoch값을 2로 나눈 나머지가 1이고 n값이 0일 때 print를 수행한다.

다음은 실행 결과 화면이다.
```
w  =  7.393, b  =  8.888
w  =  4.332, b  =  7.464
w  =  2.897, b  =  6.614
w  =  2.247, b  =  6.051
w  =  1.974, b  =  5.636
w  =  1.882, b  =  5.303
w  =  1.875, b  =  5.016
w  =  1.907, b  =  4.760
w  =  1.956, b  =  4.526
w  =  2.011, b  =  4.309
```
학습 회수에 따라 w, b값이 바뀌는 것을 확인한다.
<br>
<br>

### 반복 학습 200회 수행하기
여기서는 반복 학습 200회를 수행해 보겠다.

다음과 같이 예제를 수정한다.
```python
xs = [-1., 0., 1., 2., 3., 4.]
ys = [-2., 1., 4., 7., 10., 13.]
w = 10.
b = 10.

for epoch in range(200):

    for n in range(6):

        y = xs[n]*w + 1*b

        t = ys[n]
        E = (y - t)**2/2

        yb = y - t
        wb = yb*xs[n]
        bb = yb*1

        lr = 0.01
        w = w - lr*wb
        b = b - lr*bb
        if epoch % 20 == 1 and n == 0:
            print(f'w  = {w:6.3f}, b  = {b:6.3f}')
```
- epoch값을 0에서 200 미만까지 바꾸어가며 200회 반복을 수행한다.
- epoch값을 20으로 나눈 나머지가 1이고 n값이 0일 때 print를 수행한다.

다음은 실행 결과 화면이다.
```
w  =  7.393, b  =  8.888
w  =  2.067, b  =  4.107
w  =  2.499, b  =  2.660
w  =  2.732, b  =  1.887
w  =  2.857, b  =  1.474
w  =  2.923, b  =  1.253
w  =  2.959, b  =  1.136
w  =  2.978, b  =  1.072
w  =  2.988, b  =  1.039
w  =  2.994, b  =  1.021
```
학습 회수에 따라 w, b값이 바뀌는 것을 확인한다.  
w값은 3에, b값은 1에 가까워지는 것을 확인한다.
<br>
<br>

### 반복 학습 2000회 수행하기
여기서는 반복 학습 2000회를 수행해 보겠다.

다음과 같이 예제를 수정한다.
```python
xs = [-1., 0., 1., 2., 3., 4.]
ys = [-2., 1., 4., 7., 10., 13.]
w = 10.
b = 10.

for epoch in range(2000):

    for n in range(6):

        y = xs[n]*w + 1*b

        t = ys[n]
        E = (y - t)**2/2

        yb = y - t
        wb = yb*xs[n]
        bb = yb*1

        lr = 0.01
        w = w - lr*wb
        b = b - lr*bb
        if epoch % 200 == 1 and n == 0:
            print(f'w  = {w:6.3f}, b  = {b:6.3f}')
```
- epoch값을 0에서 2000 미만까지 바꾸어가며 반복을 2000회 수행한다.
- epoch값을 200으로 나눈 나머지가 1이고 n값이 0일 때 print를 수행한다.

다음은 실행 결과 화면이다.
```
w  =  7.393, b  =  8.888
w  =  2.997, b  =  1.011
w  =  3.000, b  =  1.000
w  =  3.000, b  =  1.000
w  =  3.000, b  =  1.000
w  =  3.000, b  =  1.000
w  =  3.000, b  =  1.000
w  =  3.000, b  =  1.000
w  =  3.000, b  =  1.000
w  =  3.000, b  =  1.000
```
학습 회수에 따라 w, b값이 바뀌는 것을 확인한다.  
w값은 3에 b값은 1에 수렴하는 것을 확인한다.
<br>
<br>

### 가중치, 편향 바꿔보기 1
여기서는 가중치와 편향 값을 바꾸어 실습을 진행해 보겠다.

다음과 같이 예제를 수정한다.
```python
xs = [-1., 0., 1., 2., 3., 4.]
ys = [-2., 1., 4., 7., 10., 13.]
w = -10.
b = 10.

for epoch in range(2000):

    for n in range(6):

        y = xs[n]*w + 1*b

        t = ys[n]
        E = (y - t)**2/2

        yb = y - t
        wb = yb*xs[n]
        bb = yb*1

        lr = 0.01
        w = w - lr*wb
        b = b - lr*bb
        if epoch % 200 == 1 and n == 0:
            print(f'w  = {w:6.3f}, b  = {b:6.3f}')
```
- 가중치 w값을 -10.으로 바꾼다.
- 편향 b값은 10.으로 둔다.

다음은 실행 결과 화면이다.
```
w  = -6.877, b  = 10.358
w  =  2.993, b  =  1.022
w  =  3.000, b  =  1.000
w  =  3.000, b  =  1.000
w  =  3.000, b  =  1.000
w  =  3.000, b  =  1.000
w  =  3.000, b  =  1.000
w  =  3.000, b  =  1.000
w  =  3.000, b  =  1.000
w  =  3.000, b  =  1.000
```
w값은 3에 b값은 1에 수렴하는 것을 확인한다.
<br>
<br>

### 가중치, 편향 바꿔보기 2
다음과 같이 예제를 수정한다.
```python
xs = [-1., 0., 1., 2., 3., 4.]
ys = [-2., 1., 4., 7., 10., 13.]
w = -100.
b = 200.

for epoch in range(2000):

    for n in range(6):

        y = xs[n]*w + 1*b

        t = ys[n]
        E = (y - t)**2/2

        yb = y - t
        wb = yb*xs[n]
        bb = yb*1

        lr = 0.01
        w = w - lr*wb
        b = b - lr*bb
        if epoch % 200 == 1 and n == 0:
            print(f'w  = {w:6.3f}, b  = {b:6.3f}')
```
- 가중치 w값을 -100.으로 바꾼다.
- 편향 b값은 200.으로 바꾼다.

다음은 실행 결과 화면이다.
```
w  = -83.789, b  = 194.356
w  =  2.884, b  =  1.385
w  =  3.000, b  =  1.001
w  =  3.000, b  =  1.000
w  =  3.000, b  =  1.000
w  =  3.000, b  =  1.000
w  =  3.000, b  =  1.000
w  =  3.000, b  =  1.000
w  =  3.000, b  =  1.000
w  =  3.000, b  =  1.000
```
w 값은 3에 b값은 1에 수렴하는 것을 확인한다.
