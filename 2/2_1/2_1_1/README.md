[Home](./../../../README.md) | [인공 지능의 딥러닝 알고리즘](./../../README.md) | [딥러닝 동작 원리 이해하기](./../README.md) | 기본 인공 신경 동작 살펴보기

## 기본 인공 신경 동작 살펴보기
다음은 앞에서 소개한 단일 인공 신경의 그림이다.  
이 인공 신경은 입력 노드 1개, 출력 노드 1개, 편향으로 구성된 단일 인공 신경이다.  
![Image](https://github.com/user-attachments/assets/3b43d176-3e69-4730-beb9-146d51f6fc63)

수식으로는 다음과 같이 표현한다.  
$y=xw+1b$

이 수식에 대해서 구체적으로 생각해 보자.  
다음과 같이 각 변수에 값을 준다.  
$x=2$  
$w=3$  
$b=1$

그러면 식은 다음과 같게 된다.  
$y=2\times3+1\times1$  
$y=?$

y는 얼마가 될까? 다음과 같이 계산해서 y는 7이 된다.  
$2\times3+1\times1=7$
<br>
<br>

### 순전파
이 상황을 그림으로 생각해보자.  
다음과 같이 x, w, b 값이 y로 흘러 들어가는 인공 신경 파이프가 있다.  
이 과정을 인공 신경의 순전파라고 한다.  
![Image](https://github.com/user-attachments/assets/fda4d200-8296-4a6c-9044-553bd087b9c6)

이 경우 y로 얼마가 나올까?  
앞에서 살펴본 대로 다음과 같은 과정을 거쳐 7이 흘러나오게 된다.  
![Image](https://github.com/user-attachments/assets/3c0e6fc6-a437-473c-958f-a3869809018d)
<br>
<br>

### 목표 값과 역전파 오차
그런데 y로 10이 나오게 하려면 들어오는 값들을 어떻게 바꿔야 할까?  
![Image](https://github.com/user-attachments/assets/794af4f6-df46-4143-94c9-a5f266f59642)

y값이 10이 되려면 3이 모자란다.  
x, w, b값을 적당히 증가시키면 y로 10에 가까운 값이 나오게 할 수 있을 것이다.  
이 과정을 자세히 살펴보자.  
이전 그림에서 y로 7이 흘러나갔는데 우리는 이 값이 10이 되기를 원한다.  
여기서 10은 목표 값이 된다.  
다음 수식에서 t는 목표 값 10을 갖는다.  
$t=10$  
$y=7$  
$y_b=y-t$  
$y_b=-3$  
$y$값은 현재 값 7인 상태이며, $y_b$는 현재 값에서 목표 값을 뺀 값 -3이 된다.  
이 때, $y_b$값을 역전파 오차라고 하며, 역전파에 사용할 오차 값이다.

표로 정리하면 다음과 같다.  
![Image](https://github.com/user-attachments/assets/5578d7fd-6a64-49ec-a01d-bfe4977609d7)
<br>
<br>

### 오차 역전파
이 상황을 그림으로 생각해 보자.  
이번엔 yb의 값이 xb, wb, bb로 거꾸로 흘러가는 상황이 된다.  
![Image](https://github.com/user-attachments/assets/7e1f3163-9dde-45a3-bb05-0ab6082edcf3)

xb, wb, bb를 어떤 기준으로 얼마나 값을 할당해야 할까?  
다음과 같은 방법을 살펴보자.
```
2는 3만큼 7로 갔어! 그러니까 -3도 3만큼 2로 돌아가게 하자!
3은 2만큼 7로 갔어! 그러니까 -3을 2만큼 3으로 돌아가게 하자!
1은 1만큼 7로 갔어! 그러니까 -3을 1만큼 1로 돌아가게 하자!
```
설득력이 있는가?  
이 방법이 바로 인공 신경에서 사용하는 오차 역전파이다.  
이 방법은 실제로 조금은 어려울 수 있는 편미분을 적용하여 얻은 방법으로 위 과정에서는 직관적인 방법으로 대체하였다.  
지금까지의 과정을 그림과 수식을 통해서 다시 한 번 정리해 보겠다.
<br>
<br>

### 순전파 정리하기
다음은 x, w, b가 y로 흘러가는 순전파를 나타낸다.   
![Image](https://github.com/user-attachments/assets/f644159a-42f5-47a6-aef8-e06449ce2541)

다음은 이 그림에 대한 수식이다.  
$xw+1b=y$

앞의 수식은 다음과 같은 의미를 갖는다.
```
x는 w만큼 y로 갔어.  x  --- w --->  y
w는 x만큼 y로 갔어.  w  --- x --->  y
b는 1만큼 y로 갔어.  b  --- 1 --->  y
```
<br>
<br>

### 역전파 정리하기
다음은 yb가 xb, wb, bb로 흘러가는 역전파를 나타낸다.  
![Image](https://github.com/user-attachments/assets/cbe47cf2-d05d-4d77-807f-6546b10311de)

우리는 다음 사항이 궁금하다.
- yb는 얼마만큼 xb로 가야해?
- yb는 얼마만큼 wb로 가야해?
- yb는 얼마만큼 bb로 가야해?

이에 대한 답은 다음과 같다.
- x가 w만큼 y로 왔으니 yb도 w만큼 xb로 가야하는 거 아니야?
  ```
   x   --- w --->  y
  xb  <--- w ---   yb
  ```
- w가 x만큼 y로 왔으니 yb도 x만큼 wb로 가야하는 거 아니야?
  ```
   w   --- x --->  y
  wb  <--- x ---   yb
  ```
- b가 1만큼 y로 왔으니 yb도 1만큼 bb로 가야하는 거 아니야?
  ```
   b   --- 1 --->  y
  bb  <--- 1 ---   yb 
  ```

이를 수식으로 정리하면 다음과 같다.  
$x_b=y_bw$  
$w_b=y_bx$  
$b_b=y_b1$

이 수식에 의해 xb, wb, yb는 다음 그림과 같이 계산된다.  
![Image](https://github.com/user-attachments/assets/c6f1ce3c-93f9-402c-9626-ef73f9c50cd0)  
(※ 여기서 xb값은 앞부분에 또 다른 인공 신경과 연결되어 있을 경우 yb처럼 해당 인공 신경으로 역전파 되는 값이다.  
역전파된 xb값은 해당 인공신경이 가중치와 편항 학습에 사용된다.)
<br>
<br>

### 최적화하기
이렇게 구한 값을 다시 다음과 같이 밀어 넣으면 될까?  
앞에서 구한 wb, bb의 값이 음수가 되기 때문에 일단 빼주어야 한다.  
그래야 원래 값이 증가하기 때문이다.  
![Image](https://github.com/user-attachments/assets/2333b634-acce-442b-ae5e-e67bf37fe177)  
(※ 여기서 x값은 상수라고 가정한다.  
x값이 앞부분에 또 다른 인공 신경과 연결되어 있을 경우엔 해당 인공 신경의 출력 값이 된다.  
여기서는 최초 입력 값이라고 가정한다.  
이련 경우 입력 층이라고 한다.)

그런데 wb, bb값이 너무 크다.  
이 상태로 계산을 하면 새로운 y값은 (2*9+4)와 같이 계산되어 22가 되게 되며, 우리가 원하는 10보다 더 큰 값이 나오게 된다.  
구체적인 계산 과정은 다음과 같다.  
$x = 2$  
$w = 3 - (-6)$  
$b = 1 - (-3)$  
$y = x \times w + b = 2 \times 9 + 4 = 22$
<br>
<br>

### 경사 하강법과 인공 신경망 학습
위 그림에 따라 새로운 w, b값을 구하는 수식은 다음과 같다.  
$w = w - aw_b$  
$b = b - ab_b$

이 수식을 경사하강법이라고 한다.  
그리고 이 수식을 적용하여 w, b 값을 갱신하는 과정을 인공 신경망의 학습이라고 한다.  
우리는 방금 전 1회의 학습을 수행하는 과정을 본 것이다.  
이 과정을 컴퓨터를 이용하여 반복 수행하면 우리가 원하는 값을 얻게 해 주는 하나짜리 인공 신경망을 만들 수 있다.
