[Home](./../../../README.md) | [인공 지능의 딥러닝 알고리즘](./../../README.md) | [딥러닝 동작 원리 이해하기](./../README.md) | 기본 인공 신경 동작 살펴보기

## 기본 인공 신경 동작 살펴보기
다음은 앞에서 소개한 단일 인공 신경의 그림이다.  
이 인공 신경은 입력 노드 1개, 출력 노드 1개, 편향으로 구성된 단일 인공 신경이다.  
![Image](https://github.com/user-attachments/assets/3b43d176-3e69-4730-beb9-146d51f6fc63)

수식으로는 다음과 같이 표현한다.  
$y=xw+1b$

이 수식에 대해서 구체적으로 생각해 보자.  
다음과 같이 각 변수에 값을 준다.  
$x=2$  
$w=3$  
$b=1$

그러면 식은 다음과 같게 된다.  
$y=2\times3+1\times1$  
$y=?$

y는 얼마가 될까? 다음과 같이 계산해서 y는 7이 된다.  
$2\times3+1\times1=7$
<br>
<br>

### 순전파
이 상황을 그림으로 생각해보자.  
다음과 같이 x, w, b 값이 y로 흘러 들어가는 인공 신경 파이프가 있다.  
이 과정을 인공 신경의 순전파라고 한다.  
![Image](https://github.com/user-attachments/assets/fda4d200-8296-4a6c-9044-553bd087b9c6)

이 경우 y로 얼마가 나올까?  
앞에서 살펴본 대로 다음과 같은 과정을 거쳐 7이 흘러나오게 된다.  
![Image](https://github.com/user-attachments/assets/3c0e6fc6-a437-473c-958f-a3869809018d)
<br>
<br>

### 목표 값과 역전파 오차
그런데 y로 10이 나오게 하려면 들어오는 값들을 어떻게 바꿔야 할까?  
![Image](https://github.com/user-attachments/assets/794af4f6-df46-4143-94c9-a5f266f59642)

y값이 10이 되려면 3이 모자란다.  
x, w, b값을 적당히 증가시키면 y로 10에 가까운 값이 나오게 할 수 있을 것이다.  
이 과정을 자세히 살펴보자.  
이전 그림에서 y로 7이 흘러나갔는데 우리는 이 값이 10이 되기를 원한다.  
여기서 10은 목표 값이 된다.  
다음 수식에서 t는 목표 값 10을 갖는다.  
$t=10$  
$y=7$  
$y_b=y-t$  
$y_b=-3$  
$y$값은 현재 값 7인 상태이며, $y_b$는 현재 값에서 목표 값을 뺀 값 -3이 된다.  
이 때, $y_b$값을 역전파 오차라고 하며, 역전파에 사용할 오차 값이다.

표로 정리하면 다음과 같다.  
![Image](https://github.com/user-attachments/assets/5578d7fd-6a64-49ec-a01d-bfe4977609d7)
<br>
<br>

### 오차 역전파
이 상황을 그림으로 생각해 보자.  
이번엔 yb의 값이 xb, wb, bb로 거꾸로 흘러가는 상황이 된다.  
![Image](https://github.com/user-attachments/assets/7e1f3163-9dde-45a3-bb05-0ab6082edcf3)

xb, wb, bb를 어떤 기준으로 얼마나 값을 할당해야 할까?  
다음과 같은 방법을 살펴보자.
```
2는 3만큼 7로 갔어! 그러니까 -3도 3만큼 2로 돌아가게 하자!
3은 2만큼 7로 갔어! 그러니까 -3을 2만큼 3으로 돌아가게 하자!
1은 1만큼 7로 갔어! 그러니까 -3을 1만큼 1로 돌아가게 하자!
```
설득력이 있는가?  
이 방법이 바로 인공 신경에서 사용하는 오차 역전파이다.  
이 방법은 실제로 조금은 어려울 수 있는 편미분을 적용하여 얻은 방법으로 위 과정에서는 직관적인 방법으로 대체하였다.  
지금까지의 과정을 그림과 수식을 통해서 다시 한 번 정리해 보겠다.
<br>
<br>

### 순전파 정리하기
다음은 x, w, b가 y로 흘러가는 순전파를 나타낸다.   
![Image](https://github.com/user-attachments/assets/f644159a-42f5-47a6-aef8-e06449ce2541)

다음은 이 그림에 대한 수식이다.  
$xw+1b=y$

앞의 수식은 다음과 같은 의미를 갖는다.
```
x는 w만큼 y로 갔어.  x  --- w --->  y
w는 x만큼 y로 갔어.  w  --- x --->  y
b는 1만큼 y로 갔어.  b  --- 1 --->  y
```
<br>
<br>

### 역전파 정리하기
다음은 yb가 xb, wb, bb로 흘러가는 역전파를 나타낸다.  
![Image](https://github.com/user-attachments/assets/cbe47cf2-d05d-4d77-807f-6546b10311de)

우리는 다음 사항이 궁금하다.
- yb는 얼마만큼 xb로 가야해?
- yb는 얼마만큼 wb로 가야해?
- yb는 얼마만큼 bb로 가야해?

이에 대한 답은 다음과 같다.
- x가 w만큼 y로 왔으니 yb도 w만큼 xb로 가야하는 거 아니야?
  ```
   x   --- w --->  y
  xb  <--- w ---   yb
  ```
- w가 x만큼 y로 왔으니 yb도 x만큼 wb로 가야하는 거 아니야?
  ```
   w   --- x --->  y
  wb  <--- x ---   yb
  ```
- b가 1만큼 y로 왔으니 yb도 1만큼 bb로 가야하는 거 아니야?
  ```
   b   --- 1 --->  y
  bb  <--- 1 ---   yb 
  ```

이를 수식으로 정리하면 다음과 같다.  
$x_b=y_bw$  
$w_b=y_bx$  
$b_b=y_b1$

이 수식에 의해 xb, wb, yb는 다음 그림과 같이 계산된다.  
![Image](https://github.com/user-attachments/assets/c6f1ce3c-93f9-402c-9626-ef73f9c50cd0)  
(※ 여기서 xb값은 앞부분에 또 다른 인공 신경과 연결되어 있을 경우 yb처럼 해당 인공 신경으로 역전파 되는 값이다.  
역전파된 xb값은 해당 인공신경이 가중치와 편항 학습에 사용된다.)
