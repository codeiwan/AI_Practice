[Home](./../../../README.md) | [인공 지능의 딥러닝 알고리즘](./../../README.md) | [활성화 함수 추가하기](./../README.md) | 활성화 함수의 필요성

## 활성화 함수의 필요성
여기서는 활성화 함수가 무엇인지, 활성화 함수는 왜 필요한지, 어떤 활성화 함수가 있는지 살펴보겠다.

### 활성화 함수는 무엇인가?
활성화 함수는 인공 신경망에 더해져 복잡한 패턴을 학습하게 해준다.  
즉, 다양한 형태의 입력 값에 대해 신경망을 거쳐 나온 출력 값을 우리가 원하는 목표 값에 가깝게 해주기가 더 쉬워진다.  
우리 두뇌에 있는 생체 신경과 비교할 때, 활성화 함수는 신경 말단에서 다음 신경으로 전달될 신호를 결정하는 시냅스와 같은 역할을 한다.  
시냅스는 이전 신경 세포가 내보내는 출력 신호를 받아 다음 신경 세포가 받아들일 수 있는 입력 신호로 형태를 변경한다.  
마찬가지로 활성화 함수는 이전 인공 신경이 내보내는 출력 신호를 받아 다음 인공 신경이 받아들일 수 있는 입력 신호로 형태를 변경해 주는 역할을 한다.  
![Image](https://github.com/user-attachments/assets/4c963b87-70e0-4513-a135-5a26fce2fd53)

### 활성화 함수는 왜 필요한가?
앞에선 언급했던 생물학적 유사성관느 별도로 인공 신경의 출력 값을 우리가 원하는 어떤 범위로 제한해준다.  
이것은 활성화 함수로의 입력이 $w*x+b$이기 때문이다.  
여기서 $w$는 인공 신경의 가중치, $x$는 입력, $b$는 그것에 더해지는 편향이다.  
이 값은 어떤 범위로 제한되지 않으면 신경망을 거치며 순식간에 아주 커지게 된다.
특히 수백만 개의 매개변수(가중치와 편향)으로 구성된 아주 깊은 신경망의 경우에는 더욱 그렇다.  
인공 신경을 거치며 반복적으로 계산되는 $w*x+b$는 factorial 연산과 같은 효과를 내며 이것은 순식간에 컴퓨터의 계산 범위를 넘어서게 된다.  
인공 신경망을 학습시키다 보면 Nan이라고 표시되는 경우가 있는데 이 경우가 그런 경우에 해당한다.  
![Image](https://github.com/user-attachments/assets/e46c7b49-78c4-4d4f-849c-1e95b4277b9b)

### 어떤 활성화 함수가 있는가?
**1 시그모이드**  
시그모이드 활성화 함수는 단지 역사적인 이유로 소개되며  
일반적으로 딥러닝에서 많이 사용되지 않는다.  
시그모이드 함수는 3층 정도로 구성된 인공 신경망에 적용될 때는 학습이 잘 되지만  
깊은 신경망에 적용될 때는 학습이 잘 되지 않는다.  
시그모이드 함수는 계산에 시간이 걸리고,  
입력 값이 아무리 크더라도 출력 값의 범위가 0에서 1사이로 매우 작아  
신경망을 거칠수록 출력값은 점점 더 작아져 0에 수렴하게 된다.
